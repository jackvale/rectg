#!/usr/bin/env python3
"""
README.md ç”Ÿæˆå™¨
ä» SQLite æ•°æ®åº“è¯»å–å·²ç»æ¸…æ´—å’Œåˆ†ç±»å¥½çš„çˆ¬è™«ç»“æœï¼Œç”Ÿæˆæ›´æ–°åçš„ README.mdã€‚

ç”¨æ³•:
    python3 scripts/generate_readme.py
"""
import argparse
import sqlite3
import sys
from datetime import datetime
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parent.parent
DB_PATH = ROOT_DIR / "data" / "rectg.db"
README_PATH = ROOT_DIR / "README.md"

# ä¸€çº§å¤§ç±»
TYPE_ORDER = [
    {"id": "channel", "name": "é¢‘é“"},
    {"id": "group", "name": "ç¾¤ç»„"},
    {"id": "bot", "name": "æœºå™¨äºº"},
]

# äºŒçº§åˆ†ç±»æ’åºè§„åˆ™ï¼ˆæŒ‰ç…§è¿™ä¸ªé¡ºåºè¾“å‡ºäºŒçº§åˆ†ç±»ï¼‰
CATEGORY_ORDER = [
    "ğŸ†• æ–°å‘ç°é¢‘é“",
    "ğŸ“° æ–°é—»å¿«è®¯",
    "ğŸ’» æ•°ç ç§‘æŠ€",
    "ğŸ‘¨â€ğŸ’» å¼€å‘è¿ç»´",
    "ğŸ”’ ä¿¡æ¯å®‰å…¨",
    "ğŸ§° è½¯ä»¶å·¥å…·",
    "â˜ï¸ ç½‘ç›˜èµ„æº",
    "ğŸ¬ å½±è§†å‰§é›†",
    "ğŸµ éŸ³ä¹éŸ³é¢‘",
    "ğŸ åŠ¨æ¼«æ¬¡å…ƒ",
    "ğŸ® æ¸¸æˆå¨±ä¹",
    "âœˆï¸ ç§‘å­¦ä¸Šç½‘",
    "ğŸª™ åŠ å¯†è´§å¸",
    "ğŸ“š å­¦ä¹ é˜…è¯»",
    "ğŸ¨ åˆ›æ„è®¾è®¡",
    "ğŸ“¡ ç¤¾åª’æ¬è¿",
    "ğŸ€ ä½“è‚²è¿åŠ¨",
    "ğŸ‘— ç”Ÿæ´»æ¶ˆè´¹",
    "ğŸŒ åœ°åŒºç¤¾ç¾¤",
    "ğŸ’¬ é—²èŠäº¤å‹",
    "ğŸ” ç¦åˆ©åƒç“œ",
    "ğŸ—‚ï¸ ç»¼åˆå¯¼èˆª",
    "ğŸŒ ç»¼åˆå…¶ä»–"
]

def format_count(count) -> str:
    """æ ¼å¼åŒ–æ•°å­—ä¸ºç²¾ç¡®æ•°å­—å­—ç¬¦ä¸²ï¼Œå¸¦åƒåˆ†ä½é€—å·ã€‚"""
    if count is None:
        return "-"
    return f"{int(count):,}"

def escape_pipe(text: str) -> str:
    """è½¬ä¹‰ Markdown è¡¨æ ¼ä¸­çš„ç®¡é“ç¬¦ã€‚"""
    if not text:
        return ""
    return text.replace("|", "\\|")

def generate_readme(conn: sqlite3.Connection) -> str:
    """ä»æ•°æ®åº“ç”Ÿæˆ README.md å†…å®¹ã€‚"""
    rows = conn.execute("""
        SELECT type, category, clean_title, clean_desc, url, count, title, description
        FROM entries
        WHERE keep = 1
        ORDER BY count DESC
    """).fetchall()

    # ç»“æ„: stats[type_id][cat_name] = [item1, item2, ...]
    tree = {
        "channel": {},
        "group": {},
        "bot": {}
    }
    
    total_kept = len(rows)

    # æ‰‹åŠ¨æ³¨å…¥çš„æ–°é¢‘é“ï¼Œåœ¨è¿™é‡Œè®°å½•å®ƒä»¬çš„ URLï¼Œé¿å…åœ¨åç»­é‡å¤æ·»åŠ 
    NEW_CHANNELS = [
        {"title": "sidehustleusï¼ˆå‰¯ä¸šï¼‰", "url": "https://t.me/sidehustleus", "description": "å…³æ³¨å‰¯ä¸šèµšé’±ã€æé’±ç»éªŒå’Œç‹¬ç«‹å¼€å‘", "count": None},
        {"title": "æŠ€æœ¯æ‹¾è’è€…", "url": "https://t.me/tech_scavenger", "description": "åˆ†äº«ä¼˜è´¨æŠ€æœ¯æ–‡ç« ã€å¼€æºé¡¹ç›®ä¸å®ç”¨å·¥å…·", "count": None},
        {"title": "ç…è›‹æ—¥æŠ¥", "url": "https://t.me/jandan_feed", "description": "æ–°é²œäº‹ã€æ— èŠå›¾ã€æ®µå­ç­‰æœ‰è¶£å†…å®¹", "count": None},
        {"title": "ä¸€ä¸ªäººçš„äº§å“", "url": "https://t.me/solo_product", "description": "ç‹¬ç«‹å¼€å‘è€…ã€äº§å“è®¾è®¡ä¸è¿è¥ç»éªŒ", "count": None},
        {"title": "æ·±å¤œåšå®¢", "url": "https://t.me/late_night_blog", "description": "æ·±å¤œé˜…è¯»æ–‡ç« ã€ä¸ªäººéšç¬”ä¸ç²¾ç¥è§’è½", "count": None},
        {"title": "ä»€ä¹ˆå€¼å¾—çœ‹", "url": "https://t.me/worth_read", "description": "æ¨èå€¼å¾—ä¸€è¯»çš„å¥½æ–‡ç« ä¸å¥½ä¹¦", "count": None},
        {"title": "ç¨‹åºå‘˜æ—¥å¸¸", "url": "https://t.me/dev_everyday", "description": "ç¨‹åºå‘˜çš„æ—¥å¸¸å·¥ä½œã€åæ§½ä¸ç»éªŒåˆ†äº«", "count": None},
        {"title": "å°ä¼—è½¯ä»¶", "url": "https://t.me/niche_software", "description": "å‘ç°ä¸åˆ†äº«å¥½ç”¨ã€æ–°å¥‡çš„å°ä¼—è½¯ä»¶", "count": None},
        {"title": "é…±é…±ã®æ—¥æŠ¥", "url": "https://t.me/jiangdaily", "description": "æ¯å¤©ä¸åªæ˜¯æ–°é—»ï¼Œæ›´æ˜¯é…±é…±çš„å‘ç°æ—¥å¸¸ï½ ç²¾é€‰æœ‰è¶£ã€æœ‰æ–™ã€æœ‰çµé­‚çš„ã€Œçƒ­é¥­ã€", "count": 137},
        {"title": "è´¢ç»é€ŸæŠ¥", "url": "https://t.me/econ_news_cn", "description": "æœ€æ–°æœ€å¿«çš„è´¢ç»æ–°é—»ä¸å¸‚åœºåŠ¨æ€èµ„è®¯", "count": None}
    ]
    custom_urls = {ch["url"] for ch in NEW_CHANNELS}

    for row in rows:
        t = row["type"]
        if t not in tree:
            continue
            
        # è¿‡æ»¤æ‰è‡ªå®šä¹‰æ³¨å…¥çš„é¢‘é“ï¼Œé˜²æ­¢é‡å¤
        if row["url"] in custom_urls:
            continue

        cat = row["category"] or "ğŸŒ ç»¼åˆå…¶ä»–"
        if cat not in tree[t]:
            tree[t][cat] = []
        tree[t][cat].append(dict(row))

    # æ³¨å…¥æ–°é¢‘é“æ¿å—
    tree["channel"]["ğŸ†• æ–°å‘ç°é¢‘é“"] = [
        {
            "type": "channel",
            "category": "ğŸ†• æ–°å‘ç°é¢‘é“",
            "clean_title": ch["title"],
            "title": ch["title"],
            "url": ch["url"],
            "count": ch["count"],
            "clean_desc": ch["description"],
            "description": ch["description"]
        } for ch in NEW_CHANNELS
    ]

    lines = []
    lines.append("# Telegram ä¼˜è´¨ä¸­æ–‡é¢‘é“ä¸ç¾¤ç»„ç²¾é€‰")
    lines.append("")
    lines.append("> **rectg** æ”¶å½• 1000+ ä¼˜è´¨ Telegram ä¸­æ–‡é¢‘é“ä¸ç¾¤ç»„ã€‚é€šè¿‡è‡ªåŠ¨åŒ–è„šæœ¬æŒç»­è·Ÿè¸ªï¼Œä¸¥æ ¼è¿‡æ»¤åƒµå°¸å·ã€ä½è´¨ä¿¡æ¯ä¸åœæ›´èŠ‚ç‚¹ï¼Œä¸ºæ‚¨æä¾›çº¯ç²¹ã€é«˜æ•ˆçš„ TG å¯¼èˆªä½“éªŒã€‚")
    lines.append("> ")
    lines.append("> âš ï¸ **å…è´£å£°æ˜**ï¼šæœ¬é¡¹ç›®ä»…ä¾›æŠ€æœ¯å­¦ä¹ ä¸ä¿¡æ¯å¯¼èˆªä½¿ç”¨ã€‚ä¸¥ç¦ä¸­å›½å¤§é™†åœ°åŒºç”¨æˆ·ä½¿ç”¨ï¼Œæ‰€æœ‰ä½¿ç”¨è€…é¡»ä¸¥æ ¼éµå®ˆæ‰€åœ¨åœ°åŒºæ³•å¾‹æ³•è§„ï¼Œä¸€åˆ‡å› è¿è§„ä½¿ç”¨äº§ç”Ÿçš„æ³•å¾‹è´£ä»»å‡ä¸æœ¬é¡¹ç›®æ— å…³ã€‚")
    lines.append("")

    # ç”Ÿæˆå„ç‰ˆå—
    for t_info in TYPE_ORDER:
        t_id = t_info["id"]
        t_name = t_info["name"]
        
        categories = tree[t_id]
        if not categories:
            continue
            
        lines.append(f"## {t_name}")
        lines.append("")
        
        # æŒ‰ç…§é¢„å®šä¹‰çš„ category é¡ºåºéå†ï¼Œå¦‚æœä¸åœ¨é¢„å®šä¹‰é‡Œåˆ™æ”¾åˆ°æœ€å
        existing_cats = set(categories.keys())
        sorted_cats = [c for c in CATEGORY_ORDER if c in existing_cats]
        sorted_cats += sorted(list(existing_cats - set(CATEGORY_ORDER)))
        
        for cat in sorted_cats:
            items = categories[cat]
            if not items:
                continue
                
            lines.append("### " + cat)
            lines.append("")
            
            for item in items:
                # ä¼˜å…ˆä½¿ç”¨ cleaned æ•°æ®ï¼Œæ— éœ€ escape_pipe å› ä¸ºä¸å†æ˜¯è¡¨æ ¼
                title = item.get("clean_title") or item.get("title") or ""
                desc = item.get("clean_desc") or item.get("description") or ""
                
                url = item.get("url", "")
                count = format_count(item.get("count"))
                
                type_id = item.get("type")
                type_label = next((t["name"] for t in TYPE_ORDER if t["id"] == type_id), "æœªçŸ¥")
                
                lines.append(f"- {title}")
                lines.append(f"  - {type_label}")
                lines.append(f"  - [{url}]({url})")
                lines.append(f"  - {count}")
                if desc:
                    lines.append(f"  - {desc}")
                
                lines.append("")
                
            lines.append("")

    # Star History ä¿æŒåœ¨åº•éƒ¨
    lines.append("## Star History")
    lines.append("")
    lines.append("[![Star History](https://starchart.cc/jackhawks/rectg.svg?variant=adaptive)](https://starchart.cc/jackhawks/rectg)")
    lines.append("")

    return "\n".join(lines).strip() + "\n"


def main():
    parser = argparse.ArgumentParser(description="README.md ç”Ÿæˆå™¨")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤è¦†ç›– README.mdï¼‰")
    args = parser.parse_args()

    if not DB_PATH.exists():
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®åº“: {DB_PATH}")
        sys.exit(1)

    conn = sqlite3.connect(str(DB_PATH))
    conn.row_factory = sqlite3.Row

    readme_content = generate_readme(conn)
    conn.close()

    out_path = Path(args.output) if args.output else README_PATH
    out_path.write_text(readme_content, encoding="utf-8")
    print(f"âœ… README å·²ç”Ÿæˆ: {out_path}")


if __name__ == "__main__":
    main()
