#!/usr/bin/env python3
"""
tg-nav.github.io é“¾æ¥æŠ“å–å™¨
ä» tg-nav çš„é¢‘é“é¡µå’Œç¾¤ç»„é¡µä¸­æå– Telegram ç”¨æˆ·åï¼Œå¯¼å…¥åˆ° links è¡¨ã€‚

æ³¨æ„: tg-nav.github.io ä½¿ç”¨ JavaScript æ¸²æŸ“å†…å®¹ï¼Œä¸»è¦å†…å®¹åœ¨é™æ€ HTML ä¸­ä¸å¯è§ã€‚
å› æ­¤æœ¬è„šæœ¬åŒæ—¶ä½¿ç”¨ä¸¤ç§ç­–ç•¥ï¼š
1. ä½¿ç”¨ requests è·å–é™æ€ HTML ä¸­çš„ t.me é“¾æ¥
2. å†…åµŒä¸€ä»½ä»æµè§ˆå™¨ä¸­é¢„æå–çš„ç”¨æˆ·ååˆ—è¡¨ä½œä¸ºè¡¥å……

ç”¨æ³•:
    python3 scripts/scrape_tgnav.py
"""
from __future__ import annotations

import re
import sqlite3
from datetime import datetime
from pathlib import Path
from urllib.parse import urlparse, parse_qs

import requests
from bs4 import BeautifulSoup

ROOT_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = ROOT_DIR / "data"
DB_PATH = DATA_DIR / "rectg.db"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
}

# éœ€è¦æ’é™¤çš„ç”¨æˆ·åï¼ˆæ¨å¹¿/é TG å†…å®¹/é€šç”¨è¯ï¼‰
EXCLUDE_USERNAMES = {
    "s", "joinchat", "proxy", "socks", "share", "iv",
}

# ---------------------------------------------------------------------------
# ä»æµè§ˆå™¨é¢„æå–çš„ç”¨æˆ·åï¼ˆtg-nav ä½¿ç”¨ JS æ¸²æŸ“ï¼Œé™æ€ HTML è·å–ä¸åˆ°è¿™äº›ï¼‰
# æœ€åæ›´æ–°: 2026-02-20
# ---------------------------------------------------------------------------
BROWSER_EXTRACTED = {
    # ç¾¤ç»„
    "simfans", "DocOfCard", "group_shouliumeiyizhifuyou",
    "TGQRYbot", "TeleindexBot", "aiso", "jisouZHbot",
    "PolarisseekBot", "So1234Bot", "zh_secretary_bot",
    "daohangbot", "damosuoyinAdminbot", "TG_index_bot",
    "qunzudaquan_bot", "tg_chs_bot", "SearcheeBot",
    "kuqun_bot", "dh2345_bot", "quannengsobot",
    "TeleSearchMain_bot", "UniversityAlliance_Info",
    "airport_chat", "lilydeyaa", "se_talk", "MFJD99",
    "MoeMeta", "KinhDownChat", "Brahmanjg",
    "OnlineAppleUserGroup", "WeiyouTuwu1", "shufm",
    "sharing_books4u", "shumozyfx", "ReadfineChat",
    "Waikan2023", "paoluqun", "Yiology", "Liyuxuanxue",
    "ubuntuzh", "pythonzh", "P_Y_T_H_O_N",
    "open_source_community", "coder_ot", "V2EXPro",
    "goV2EX", "pan_icu", "GolangCN", "vpschat",
    "dockertutorial", "Clanguagezh", "AndroidDevCn",
    "vpsxinhaoqi", "tgcnx", "haijiaosheque", "tgzhcn",
    "CNderivatives", "hezu1", "wikipedia_zh_n",
    "jichang_user", "gpt_user", "googlevoice", "GVsPbot",
    "zaihuachat", "jianjiaoQUN", "douban_discuss",
    "yummy_best", "NewlearnerGroup", "kejiquchat",
    "hengjiazhihui", "cosplaysharegroup", "xiafengforever",
    "xpyanjiusuo1", "vGiJ3ukDAa80ZDhl", "nekopara",
    "acg_moe", "tsukigroup", "MEME981211", "mio_house",
    "QingjuACG_Chat", "galgame", "abcd13354",
    "RhineDiscussionRoom",
    # é¢‘é“ + ç¾¤ç»„å…±æœ‰
    "appdododo", "pdcn3", "ruanlu", "lajilao",
    "AppleTVPlus", "KernelSU_group", "ham002",
    "samsung_cn", "xiaomi6666", "cemiuiler", "nasfan",
    "DHDAXCW", "homelab520", "MaoYingShi", "shumeipai",
    "blacktechsharing", "appmiao", "Riocoolapk",
    "ycq_777", "loopdns", "wolfgang88", "LdFriend",
    "plus8889", "youyousharegroup", "nagram_group",
    "Loon0x00", "loveapps", "QuanXApp", "Notionso",
    "netflixchina", "appinn",
    # é¢‘é“é¡µ
    "Aliyundrive_Share_Group", "Aliyundrive_Share_Channel",
    "photo100percent", "shadiaogenjudi", "xin_jing_bao",
    "yppshare", "alyd_g", "cnphotog", "shadiaoo",
    "xinjingdailychatroom", "shaodiaotu_chat", "ywtrzm",
}


def init_db(db_path: Path) -> sqlite3.Connection:
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ã€‚"""
    db_path.parent.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(str(db_path))
    conn.row_factory = sqlite3.Row
    conn.execute("""
        CREATE TABLE IF NOT EXISTS links (
            id              INTEGER PRIMARY KEY AUTOINCREMENT,
            url             TEXT NOT NULL UNIQUE,
            username        TEXT,
            name            TEXT,
            type_hint       TEXT,
            created_at      TEXT NOT NULL,
            updated_at      TEXT NOT NULL
        )
    """)
    conn.commit()
    return conn


def extract_tme_usernames(html: str) -> set[str]:
    """ä» HTML ä¸­æå– t.me ç”¨æˆ·åã€‚"""
    soup = BeautifulSoup(html, "lxml")
    usernames = set()

    for a_tag in soup.find_all("a", href=True):
        href = a_tag["href"]

        # æ¨¡å¼ 1: tg-nav.github.io/detail/{username}
        m = re.search(r'tg-nav\.github\.io/detail/([A-Za-z0-9_]+)', href)
        if m:
            usernames.add(m.group(1))
            continue

        # æ¨¡å¼ 2: tg-nav.github.io/go/?username={username}
        m = re.search(r'tg-nav\.github\.io/go/\?username=([A-Za-z0-9_]+)', href)
        if m:
            usernames.add(m.group(1))
            continue

        # æ¨¡å¼ 3: t.me/{username}
        parsed = urlparse(href)
        if parsed.hostname in ("t.me", "www.t.me"):
            path = parsed.path.strip("/")
            if not path or path.startswith("joinchat/") or path.startswith("+"):
                continue
            username = path.split("/")[0]
            if username in EXCLUDE_USERNAMES:
                continue
            if re.match(r'^[A-Za-z][A-Za-z0-9_]{3,}$', username):
                usernames.add(username)

    return usernames


def main():
    print("=" * 60)
    print("  tg-nav.github.io é“¾æ¥æŠ“å–å™¨")
    print("=" * 60)

    conn = init_db(DB_PATH)
    session = requests.Session()
    session.headers.update(HEADERS)

    # åˆå¹¶æ‰€æœ‰ç”¨æˆ·åæ¥æº
    all_usernames: set[str] = set(BROWSER_EXTRACTED)

    # å°è¯•ä»é™æ€ HTML è¡¥å……ï¼ˆåªèƒ½è·å–æ¨å¹¿åŒºçš„ t.me é“¾æ¥ï¼‰
    pages = [
        "https://tg-nav.github.io/",
        "https://tg-nav.github.io/group",
    ]
    for page_url in pages:
        print(f"\nğŸ“¡ æ­£åœ¨æŠ“å–: {page_url}")
        try:
            resp = session.get(page_url, timeout=30)
            resp.raise_for_status()
            html_usernames = extract_tme_usernames(resp.text)
            new = html_usernames - all_usernames
            print(f"   é™æ€ HTML ä¸­æ‰¾åˆ° {len(html_usernames)} ä¸ªç”¨æˆ·å, æ–°å¢ {len(new)} ä¸ª")
            all_usernames |= html_usernames
        except requests.RequestException as e:
            print(f"   âš ï¸ è¯·æ±‚å¤±è´¥ (å°†ä½¿ç”¨é¢„æå–æ•°æ®): {e}")

    print(f"\nğŸ“Š åˆè®¡å»é‡åå…± {len(all_usernames)} ä¸ªç”¨æˆ·å")

    # å†™å…¥æ•°æ®åº“
    now = datetime.now().isoformat()
    inserted = 0
    skipped = 0

    for username in sorted(all_usernames):
        url = f"https://t.me/{username}"
        name = f"[tg-nav] {username}"

        existing = conn.execute(
            "SELECT id FROM links WHERE url = ? OR username = ?",
            (url, username),
        ).fetchone()

        if existing:
            skipped += 1
            continue

        conn.execute("""
            INSERT INTO links (url, username, name, type_hint, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (url, username, name, None, now, now))
        inserted += 1

    conn.commit()

    # æ±‡æ€»
    total = conn.execute("SELECT COUNT(*) FROM links").fetchone()[0]
    tgnav_count = conn.execute(
        "SELECT COUNT(*) FROM links WHERE name LIKE '[tg-nav]%'"
    ).fetchone()[0]

    conn.close()

    print(f"\n{'=' * 60}")
    print(f"  ğŸ“Š æ±‡æ€»")
    print(f"  æœ¬æ¬¡æ–°å¢: {inserted}")
    print(f"  æœ¬æ¬¡è·³è¿‡(å·²å­˜åœ¨): {skipped}")
    print(f"  tg-nav æ¥æºæ€»è®¡: {tgnav_count}")
    print(f"  links è¡¨æ€»è®¡: {total}")
    print(f"  æ•°æ®åº“: {DB_PATH}")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    main()
